---
title: 3월 5주차 내맘대로 Weekly Insights
layout: post
tag: [weekly_insights]
toc: true
---

3월 5주차, 한 주 동안 개인적으로 흥미롭게 본 인사이트들을 소개합니다 :)

### [코드 품질 개선 기법 시리즈 소개](https://techblog.lycorp.co.jp/ko/techniques-for-improving-code-quality-list)
LY Corporation(소프트뱅크 그룹과 네이버가 합작한 A홀딩스 산하 종합 IT 기업)에서 작성한, 널리 적용 가능한 코드 품질 개선 기법 시리즈다.  
현재 6편까지 올라와 있고, 범용적으로 적용할 수 있는 유용한 내용이 많다.  

요즘 사이드 프로젝트에서 코틀린으로 백엔드 서버를 만들고 있는데, 자바와 비슷하면서도 다른 점이 많아서 이 시리즈가 꽤 도움이 된다.  
예를 들어, [6편: 마구 자를 것인가 반듯하게 자를 것인가](https://techblog.lycorp.co.jp/ko/techniques-for-improving-code-quality-6)에선 가독성 있게 체인을 구성하는 방법이 인상적이었고, [3편: 전략 없는 전략](https://techblog.lycorp.co.jp/ko/techniques-for-improving-code-quality-3)의 ‘로직을 타입에 포함시키는 전략’은 바로 프로젝트에 써먹을 수 있을 만큼 실용적이었다.

---

### [내가 아는 최악의 프로그래머](https://news.hada.io/topic?id=19914)
최근 면접을 보면서 "일 잘하는 개발자란 어떤 사람인가요?"라는 질문을 종종 던졌다.  
답변은 제각각이었지만, 공통된 건 정량적인 평가가 어렵다는 거였다.  

이 아티클도 마찬가지다. 개인의 성과를 측정하려 했지만 결국 실패했다고 말한다.  
보다 보면 이런 고민들이 꼬리를 물게 된다:

1. 팀 내에서 개인 성과를 어떻게 공정하게 평가할 수 있을까?  
   → 정량화가 안 된다면, 신뢰는 어떻게 쌓고 유지해야 할까?
2. 페어 프로그래밍이나 멘토링 같은 활동은 정량적으로 평가할 수 있을까?  
   → 성과 측정을 강제하는 조직 문화는 어떤 부작용을 낳을까?
3. 팀 성과를 높이기 위해 개인 기여도를 어떻게 균형 있게 바라봐야 할까?  
   → 어떤 피드백이나 평가 방식이 더 적절할까?

질문은 계속 떠오르지만, 쉽게 답하긴 어렵다.  
그래도 질문을 멈추지 말아야 한다.  
_“품고 있는 의문의 수준이 삶의 수준을 결정한다.”_  
질문을 살아가자.

---

### [AWS RDS 비용 폭탄 사건](https://brunch.co.kr/@cebi750/10)
사이드 프로젝트를 하다 보니 AWS 비용 탭을 자주 들여다보게 된다.  
예산 알림도 설정해두고, 이상 탐지 메일도 받아보게 했는데도… 뭔가 불안하다.  

이 글에선 DB 설정 하나 바꿨을 뿐인데, 분당 IOPS가 10~20만에서 3500만까지 치솟았다고 한다.  
그 결과는? 약 $3200의 비용. 듣기만 해도 아찔하다.  

> **클라우드를 쓴다는 건, 개발자 각자에게 한도 무제한 법인카드를 쥐여주는 것과 같다.**

이 말이 정말 와닿는다.

---

### [실무에서 적용하는 테스트 코드 작성 방법과 노하우 Part 3: Given 지옥에서 벗어나기 - 스노우볼을 굴려라](https://tech.kakaopay.com/post/given-test-code-2/)
테스트 코드는 보통 given-when-then 구조로 작성한다.  
하지만 서비스나 도메인이 복잡해지면 given, 즉 사전 준비 코드가 너무 길어진다.  

코틀린에선 함수 파라미터에 기본값을 주는 방식으로 어느 정도 해결할 수 있다.  
(자바는 그게 안 되니까 보통 빌더 패턴을 쓴다.)  
근데 멀티모듈 환경에선 이런 방식이 잘 안 통한다.  

이 글에선 그런 경우 `java-test-fixtures`를 사용하는 걸 추천한다.  
사이드 프로젝트를 멀티모듈로 리팩토링할 때 꼭 써먹어 봐야겠다.

---

### [코드 리뷰 요정, CodeRabbit이 나타났다 🐰](https://tech.inflab.com/20250303-introduce-coderabbit/)
AI가 발전하면서 개발자를 도와주는 도구들이 정말 많아졌다.  
이젠 commit 메시지를 자동으로 써주고, 오류도 잡아주고, 심지어 AI와 페어 프로그래밍도 가능하다.  

PR을 올리면 코드 리뷰를 자동으로 해주는 도구들도 꽤 많이 나왔다.  
예를 들면 [Code Review GPT](https://github.com/marketplace/actions/code-review-gpt), 
[AI Code Reviewer](https://github.com/marketplace/actions/ai-code-review-action) 같은 것들.  
GitHub Marketplace에서 쉽게 찾아볼 수 있다.  

이 아티클은 인프랩에서 만든 **CodeRabbit**을 사용해본 후기다.  
GitHub에 있는 기존 툴들과 뭐가 다른지는 아직 잘 모르겠는데, 직접 써보면 차이가 느껴질지도 모르겠다.
